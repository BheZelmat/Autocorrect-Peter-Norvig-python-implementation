{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrect\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Overview\n",
    "\n",
    "We use autocorrect every day on Our cell phone and computer. In this Notebook, we will explore what really goes on behind the scenes. Of course, the model we are about to implement is not identical to the one used in our phones, but it is still quite good. \n",
    "\n",
    "Steps to take : \n",
    "\n",
    "- Get a word count given a corpus\n",
    "- Get a word probability in the corpus \n",
    "- Manipulate strings \n",
    "- Filter strings \n",
    "- Implement Minimum edit distance to compare strings and to help find the optimal path for the edits. \n",
    "- Understand how dynamic programming works\n",
    "\n",
    "\n",
    "Similar systems are used everywhere. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Edit Distance\n",
    "\n",
    "In this Notebook, we will implement a model that correct words that are 1 and 2 edit distances away. \n",
    "- We say two words are n edit distance away from each other when we need n edits to change one word into another. \n",
    "\n",
    "An edit could consist of one of the following options: \n",
    "\n",
    "- Delete (remove a letter): ‘hat’ => ‘at, ha, ht’\n",
    "- Switch (swap 2 adjacent letters): ‘eta’ => ‘eat, tea,...’\n",
    "- Replace (change 1 letter to another): ‘jat’ => ‘hat, rat, cat, mat, ...’\n",
    "- Insert (add a letter): ‘te’ => ‘the, ten, ate, ...’\n",
    "\n",
    "We will be using the four methods above to implement an Auto-correct. \n",
    "- To do so, we will need to compute probabilities that a certain word is correct given an input. \n",
    "\n",
    "This auto-correct we are about to implement was first created by [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) in 2007. \n",
    "- His [original article](https://norvig.com/spell-correct.html) is a useful reference for this Notebook.\n",
    "\n",
    "The goal of our spell check model is to compute the following probability:\n",
    "\n",
    "$$P(c|w) = \\frac{P(w|c)\\times P(c)}{P(w)} \\tag{Eqn-1}$$\n",
    "\n",
    "The equation above is [Bayes Rule](https://en.wikipedia.org/wiki/Bayes%27_theorem). \n",
    "- Equation 1 says that the probability of a word being correct $P(c|w) $is equal to the probability of having a certain word $w$, given that it is correct $P(w|c)$, multiplied by the probability of being correct in general $P(C)$ divided by the probability of that word $w$ appearing $P(w)$ in general.\n",
    "- To compute equation 1, we will first import a dataset (shakespeare dataset) and then create all the probabilities that you need using that dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1- process_data\n",
    "The first task is to read in a file called **'shakespeare.txt'** which is found in the \"data/\"  directory.\n",
    "\n",
    "Implement the function `process_data` which \n",
    "\n",
    "1) Reads in a corpus (text file)\n",
    "\n",
    "2) Changes everything to lowercase\n",
    "\n",
    "3) Returns a list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file_name which is found in your current directory. You just have to read it in. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus (text file you read) in lower case. \n",
    "    \"\"\"\n",
    "    words = [] # return this variable correctly\n",
    "\n",
    "    \n",
    "    \n",
    "    with open(file_name,'r') as file:\n",
    "        txt=file.read()\n",
    "    txt=txt.lower()\n",
    "    words=re.findall('\\w+',txt)\n",
    "    #Convert every word to lower case and return them in a list.\n",
    "    \n",
    "    \n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, in the following cell, 'words' is converted to a python `set`. This eliminates any duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
      "There are 6116 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_l = process_data('data/shakespeare.txt')\n",
    "vocab = set(word_l)  # this will be your new vocabulary\n",
    "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  1.2 - get_count\n",
    "\n",
    "Implement a `get_count` function that returns a dictionary\n",
    "- The dictionary's keys are words\n",
    "- The value for each word is the number of times that word appears in the corpus. \n",
    "\n",
    "For example, given the following sentence: **\"I am happy because I am learning Data Science\"**, your dictionary should return the following: \n",
    "<table style=\"width:20%\">\n",
    "\n",
    "  <tr>\n",
    "    <td> <b>Key </b>  </td>\n",
    "    <td> <b>Value </b> </td> \n",
    "\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> I  </td>\n",
    "    <td> 2</td> \n",
    " \n",
    "  </tr>\n",
    "   \n",
    "  <tr>\n",
    "    <td>am</td>\n",
    "    <td>2</td> \n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>happy</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>because</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>learning</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Data</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Science</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_count(word_l):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''\n",
    "    \n",
    "    word_count_dict = {}  # fill this with word counts\n",
    "    \n",
    "    word_count_dict=Counter(word_l)\n",
    "    \n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 key values pairs\n",
      "The count for the word 'thee' is 240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_count_dict = get_count(word_l)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3- get_probs\n",
    "Given the dictionary of word counts, we will compute the probability that each word will appear if randomly selected from the corpus of words.\n",
    "\n",
    "$$P(w_i) = \\frac{C(w_i)}{M} \\tag{Eqn-2}$$\n",
    "where \n",
    "\n",
    "$C(w_i)$ is the total number of times $w_i$ appears in the corpus.\n",
    "\n",
    "$M$ is the total number of words in the corpus.\n",
    "\n",
    "For example, the probability of the word '**am**' in the sentence **'I am happy because I am learning Data Science'** is:\n",
    "\n",
    "$$P(am) = \\frac{C(w_i)}{M} = \\frac {2}{9} \\tag{Eqn-3}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}  # return the probs\n",
    "    \n",
    "    \n",
    "    \n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key]=word_count_dict[key]/sum(word_count_dict.values())\n",
    "    \n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 6116\n",
      "P('thee') is 0.0045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('thee') is {probs['thee']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - String Manipulations\n",
    "\n",
    "Now that we have computed $P(w_i)$ for all the words in the corpus, we will write a few functions to manipulate strings so that we can edit the erroneous strings and return the right spellings of the words. \n",
    "\n",
    "In this section, we will implement four functions: \n",
    "\n",
    "* `delete_letter`: given a word, it returns all the possible strings that have **one character removed**. \n",
    "* `switch_letter`: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
    "* `replace_letter`: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
    "* `insert_letter`: given a word, it returns all the possible strings that have an **additional character inserted**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 - delete_letter\n",
    "\n",
    "**Implementation** of the function  `delete_letter()` means that, given a word, returns a list of strings with one character deleted. \n",
    "\n",
    "For example, given the word **nice**, it would return the set: {'ice', 'nce', 'nic', 'nie'}. \n",
    "\n",
    "**Step 1:** Create a list of 'splits'. This is all the ways you can split a word into Left and Right: For example,   \n",
    "'nice is split into : `[('', 'nice'), ('n', 'ice'), ('ni', 'ce'), ('nic', 'e'), ('nice', '')]`\n",
    "This is common to all four functions (delete, replace, switch, insert).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** This is specific to `delete_letter`. Here, we are generating all words that result from deleting one character.    \n",
    "\n",
    "For our 'nice' example you get: \n",
    "['ice', 'nce', 'nie', 'nic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def delete_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    \n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        split_l.append((word[:i], word[i:]))\n",
    "        delete_l.append(word[:i] + word[i+1:])\n",
    "    \n",
    "\n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return  delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word cans, \n",
      "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's')], \n",
      "delete_l = ['ans', 'cns', 'cas', 'can']\n"
     ]
    }
   ],
   "source": [
    "delete_word_l = delete_letter(word=\"cans\",\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of delete_letter('at') is 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Number of outputs of delete_letter('at') is {len(delete_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2- switch_letter\n",
    "\n",
    "Implementation of the switch letter function takes in a word and returns a list of all the possible switches of two letters **that are adjacent to each other**. \n",
    "- For example, given the word 'eta', it returns {'eat', 'tea'}, but does not return 'ate'.\n",
    "\n",
    "**Step 1:** is the same as in delete_letter()  \n",
    "**Step 2:** A list comprehension which forms strings by swapping adjacent letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "def switch_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "  \n",
    "    for i in range(len(word)):\n",
    "        \n",
    "        split_l.append((word[:i], word[i:]))\n",
    "        if(i<len(word)-1):\n",
    "            switch_l.append(word[:i] + word[i+1] + word[i] + word[i+2:])\n",
    "    \n",
    "\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "    \n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = eta \n",
      "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a')] \n",
      "switch_l = ['tea', 'eat']\n"
     ]
    }
   ],
   "source": [
    "switch_word_l = switch_letter(word=\"eta\",\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of switch_letter('at') is 1\n"
     ]
    }
   ],
   "source": [
    "# test # 2\n",
    "print(f\"Number of outputs of switch_letter('at') is {len(switch_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3- Replace_letter\n",
    "The replace letter function takes in a word and returns a list of strings with one **replaced letter** from the original word. \n",
    "\n",
    "**Step 1:** is the same as in `delete_letter()`\n",
    "\n",
    "**Step 2:** A list comprehension which form strings by replacing letters.  \n",
    "\n",
    "**Step 3:** Remove the original input letter from the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    replace_set=[]\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        \n",
    "        split_l.append((word[:i], word[i:]))\n",
    "        for j in range (len(letters)):\n",
    "            if(word[i]!=letters[j]):\n",
    "                replace_set.append(word[0:i]+letters[j]+word[i+1:])\n",
    "    \n",
    "  \n",
    "    # turn the set back into a list and sort it, for easier viewing\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = can \n",
      "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
      "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
     ]
    }
   ],
   "source": [
    "replace_l = replace_letter(word='can',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of replace_letter('at') is 50\n"
     ]
    }
   ],
   "source": [
    "# test # 2\n",
    "print(f\"Number of outputs of replace_letter('at') is {len(replace_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.4- insert_letter\n",
    "\n",
    "The insert letter function takes in a word and returns a list with a letter inserted at every offset.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "\n",
    "    for i in range(len(word)+1):\n",
    "        split_l.append((word[:i], word[i:]))\n",
    "        for j in range(len(letters)):\n",
    "            insert_l.append(word[:i] +letters[j] +word[i:])\n",
    "    \n",
    "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    \n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word at \n",
      "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
      "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
      "Number of strings output by insert_letter('at') is 78\n"
     ]
    }
   ],
   "source": [
    "insert_l = insert_letter('at', True)\n",
    "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Combining the Edits\n",
    "\n",
    "Now that we have implemented the string manipulations, we will create two functions that, given a string, will return all the possible single and double edits on that string. These will be `edit_one_letter()` and `edit_two_letters()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 - Edit One Letter\n",
    "\n",
    "\n",
    "\n",
    "The role of the function is to get all the possible edits that are one edit away from a word. The edits  consist of the replace, insert, delete, and optionally the switch operation. we should use the previous functions we have already implemented to complete this function. The 'switch' function  is a less common edit function, so its use will be selected by an \"allow_switches\" input argument.\n",
    "\n",
    "Note that those functions return *lists* while this function should return a *python set*. Utilizing a set eliminates any duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "\n",
    "    if(allow_switches):\n",
    "        edit_one_set=set(insert_letter(word)+delete_letter(word)+switch_letter(word)+replace_letter(word))\n",
    "    else:\n",
    "        edit_one_set=set(insert_letter(word)+delete_letter(word)+replace_letter(word))\n",
    "\n",
    "    \n",
    "    # return this as a set and not a list !\n",
    "    return set(edit_one_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word at \n",
      "edit_one_l \n",
      "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
      "\n",
      "The type of the returned object should be a set <class 'set'>\n",
      "Number of outputs from edit_one_letter('at') is 129\n"
     ]
    }
   ],
   "source": [
    "tmp_word = \"at\"\n",
    "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
    "# turn this into a list to sort it, in order to view it\n",
    "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
    "\n",
    "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
    "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
    "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 - Edit Two Letters\n",
    "\n",
    "\n",
    "\n",
    "Now we can generalize this to implement to get two edits on a word. To do so, we would have to get all the possible edits on a single word and then for each modified word, we would have to modify it again. \n",
    "`edit_two_letters` function  returns a set of words that are two edits away. Note that creating additional edits based on the `edit_one_letter` function may 'restore' some one_edits to zero or one edits. That is allowed here. This is accounted for in get_corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "\n",
    "    edit_one=edit_one_letter(word,allow_switches)\n",
    "    for word2 in edit_one:\n",
    "        \n",
    "        \n",
    "        edit_two_set.update(edit_one_letter(word2,allow_switches))\n",
    "        \n",
    "    \n",
    "    # return this as a set instead of a list\n",
    "    return set(edit_two_set)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings with edit distance of two: 2654\n",
      "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
      "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
      "The data type of the returned object should be a set <class 'set'>\n",
      "Number of strings that are 2 edit distances from 'at' is 7154\n"
     ]
    }
   ],
   "source": [
    "tmp_edit_two_set = edit_two_letters(\"a\")\n",
    "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
    "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
    "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
    "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
    "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
    "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "### 3.3 - Suggest Spelling Suggestions\n",
    "\n",
    "Now we will use the `edit_two_letters` function to get a set of all the possible 2 edits on the given word. We will then use those strings to get the most probable word you meant to type a.k.a your typing suggestion.\n",
    "\n",
    "\n",
    "### ** `get_corrections`**\n",
    "The `get_corrections` function returns a list of zero to n possible suggestion tuples of the form (word, probability_of_word). \n",
    "\n",
    "The 'suggestion algorithm' should follow this logic: \n",
    "* If the word is in the vocabulary, suggest the word. \n",
    "* Otherwise, if there are suggestions from `edit_one_letter` that are in the vocabulary, use those. \n",
    "* Otherwise, if there are suggestions from `edit_two_letters` that are in the vocabulary, use those. \n",
    "* Otherwise, suggest the input word.*  \n",
    "* The idea is that words generated from fewer edits are more likely than words with more edits.\n",
    "\n",
    "\n",
    "Note: \n",
    "- Edits of two letters may 'restore' strings to either zero or one edit. This algorithm accounts for this by preferentially selecting lower distance edits first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_corrections(word, probs, vocab, n=2, verbose=False):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "\n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    " \n",
    "    # Step 1: if the word is in the vocabulary, suggest the word\n",
    "    if word in vocab:\n",
    "        suggestions.append(word)\n",
    "    else:\n",
    "        # Step 2: otherwise, use suggestions from edit_one_letter\n",
    "        one_edit = set(edit_one_letter(word))\n",
    "        suggestions.extend(set(word for word in one_edit if word in vocab))\n",
    "        \n",
    "        # Step 3: if no valid suggestions from one edit, use suggestions from edit_two_letters\n",
    "        if not suggestions:\n",
    "            two_edits = set(edit_two_letters(word))\n",
    "            suggestions.extend(set(word for word in two_edits if word in vocab))\n",
    "\n",
    "        # Step 4: if no suggestions are found, return the input word itself\n",
    "        if not suggestions:\n",
    "            suggestions.append(word)\n",
    "\n",
    "    # Calculate probability of suggestions and return the top n\n",
    "    prob_suggestions = {w: probs.get(w, 0) for w in suggestions}\n",
    "    n_best = sorted(prob_suggestions.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "\n",
    "    \n",
    "    if verbose: \n",
    "        print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
    "        \n",
    "\n",
    "\n",
    "    return n_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  dys \n",
      "suggestions =  ['dye', 'days']\n",
      "word 0: days, probability 0.000410\n",
      "word 1: dye, probability 0.000019\n",
      "data type of corrections <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Test The implementation - PS :  feel free to try other words in my word\n",
    "my_word = 'dys' \n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
    "\n",
    "print(f\"data type of corrections {type(tmp_corrections)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4 - Minimum Edit Distance\n",
    "\n",
    "Now that we have implemented our auto-correct, how do we evaluate the similarity between two strings? For example: 'waht' and 'what'\n",
    "\n",
    "Also how do we efficiently find the shortest path to go from the word, 'waht' to the word 'what'?\n",
    "\n",
    "We will implement a dynamic programming system that will tell us the minimum number of edits required to convert a string into another string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 - Dynamic Programming\n",
    "\n",
    "Dynamic Programming  breaks a problem down into subproblems which can be combined to form the final solution. Here, given a string source[0..i] and a string target[0..j], we will compute all the combinations of substrings[i, j] and calculate their edit distance.\n",
    "To do this efficiently, we will use a table to maintain the previously computed substrings and use those to calculate larger substrings.\n",
    "\n",
    "We have to create a matrix and update each element in the matrix as follows:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Initialization}$$\n",
    "\n",
    "\\begin{align}\n",
    "D[0,0] &= 0 \\\\\n",
    "D[i,0] &= D[i-1,0] + del\\_cost(source[i]) \\tag{4}\\\\\n",
    "D[0,j] &= D[0,j-1] + ins\\_cost(target[j]) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\\text{Per Cell Operations}$$\n",
    "\n",
    "\\begin{align}\n",
    "\n",
    " \\\\D[i,j] =min\n",
    "\\begin{cases}\n",
    "D[i-1,j] + del\\_cost\\\\\n",
    "D[i,j-1] + ins\\_cost\\\\\n",
    "D[i-1,j-1] + \\left\\{\\begin{matrix}\n",
    "rep\\_cost; & if src[i]\\neq tar[j]\\\\\n",
    "0 ; & if src[i]=tar[j]\n",
    "\\end{matrix}\\right.\n",
    "\\end{cases}\n",
    "\\tag{5}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So converting the source word **play** to the target word **stay**, using an input cost of one, a delete cost of 1, and replace cost of 2 would give you the following table:\n",
    "<table style=\"width:20%\">\n",
    "\n",
    "  <tr>\n",
    "    <td> <b> </b>  </td>\n",
    "    <td> <b># </b>  </td>\n",
    "    <td> <b>s </b>  </td>\n",
    "    <td> <b>t </b> </td> \n",
    "    <td> <b>a </b> </td> \n",
    "    <td> <b>y </b> </td> \n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td> <b>  #  </b></td>\n",
    "    <td> 0</td> \n",
    "    <td> 1</td> \n",
    "    <td> 2</td> \n",
    "    <td> 3</td> \n",
    "    <td> 4</td> \n",
    " \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>  p  </b></td>\n",
    "    <td> 1</td> \n",
    " <td> 2</td> \n",
    "    <td> 3</td> \n",
    "    <td> 4</td> \n",
    "   <td> 5</td>\n",
    "  </tr>\n",
    "   \n",
    "  <tr>\n",
    "    <td> <b> l </b></td>\n",
    "    <td>2</td> \n",
    "    <td>3</td> \n",
    "    <td>4</td> \n",
    "    <td>5</td> \n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td> <b> a </b></td>\n",
    "    <td>3</td> \n",
    "     <td>4</td> \n",
    "     <td>5</td> \n",
    "     <td>4</td>\n",
    "     <td>5</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td> <b> y </b></td>\n",
    "    <td>4</td> \n",
    "      <td>5</td> \n",
    "     <td>6</td> \n",
    "     <td>5</td>\n",
    "     <td>4</td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations used in this algorithm are 'insert', 'delete', and 'replace'. These correspond to the functions that you defined earlier: insert_letter(), delete_letter() and replace_letter(). switch_letter() is not used here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the formula for $D[i,j]$  is equivalent to:\n",
    "\n",
    "\\begin{align}\n",
    " \\\\\n",
    "D[i,j] =min\n",
    "\\begin{cases}\n",
    "D[i-1,j] + del\\_cost\\\\\n",
    "D[i,j-1] + ins\\_cost\\\\\n",
    "D[i-1,j-1] + \\left\\{\\begin{matrix}\n",
    "rep\\_cost; & if src[i]\\neq tar[j]\\\\\n",
    "0 ; & if src[i]=tar[j]\n",
    "\\end{matrix}\\right.\n",
    "\\end{cases}\n",
    "\\tag{5}\n",
    "\\end{align}\n",
    "\n",
    "The variable `sub_cost` (for substitution cost) is the same as `rep_cost`; replacement cost.  We will stick with the term \"replace\" whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2- min_edit_distance\n",
    "\n",
    "Again, the word \"substitution\" appears in the figure, but think of this as \"replacement\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
    "    '''\n",
    "    Input: \n",
    "        source: a string corresponding to the string you are starting with\n",
    "        target: a string corresponding to the string you want to end with\n",
    "        ins_cost: an integer setting the insert cost\n",
    "        del_cost: an integer setting the delete cost\n",
    "        rep_cost: an integer setting the replace cost\n",
    "    Output:\n",
    "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
    "        med: the minimum edit distance (med) required to convert the source string to the target\n",
    "    '''\n",
    "    # use deletion and insert cost as  1\n",
    "    m = len(source) \n",
    "    n = len(target) \n",
    "    #initialize cost matrix with zeros and dimensions (m+1,n+1) \n",
    "    D = np.zeros((m+1, n+1), dtype=int) \n",
    "    \n",
    "   \n",
    "    \n",
    "    # Fill in column 0, from row 1 to row m, both inclusive\n",
    "    for row in range(1,m+1): # Replace None with the proper range\n",
    "        D[row,0] = D[row-1,0]+del_cost\n",
    "        \n",
    "    # Fill in row 0, for all columns from 1 to n, both inclusive\n",
    "    for col in range(1,n+1): # Replace None with the proper range\n",
    "        D[0,col] = D[0,col-1]+ins_cost\n",
    "        \n",
    "    # Loop through row 1 to row m, both inclusive\n",
    "    for row in range(1,m+1):\n",
    "        \n",
    "        # Loop through column 1 to column n, both inclusive\n",
    "        for col in range(1,n+1):\n",
    "            \n",
    "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
    "            r_cost = rep_cost\n",
    "            \n",
    "            # Check to see if source character at the previous row\n",
    "            # matches the target character at the previous column, \n",
    "            if source[row-1]==target[col-1]: # Replace None with a proper comparison\n",
    "                # Update the replacement cost to 0 if source and target are the same\n",
    "                r_cost = 0\n",
    "                \n",
    "            # Update the cost at row, col based on previous entries in the cost matrix\n",
    "            # Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)\n",
    "            D[row,col] = min(D[row-1,col]+del_cost,D[row,col-1]+ins_cost,D[row-1,col-1]+r_cost)\n",
    "            \n",
    "    # Set the minimum edit distance with the cost found at row m, column n \n",
    "    med = D[m,n]\n",
    "    \n",
    "\n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  4 \n",
      "\n",
      "   #  s  t  a  y\n",
      "#  0  1  2  3  4\n",
      "p  1  2  3  4  5\n",
      "l  2  3  4  5  6\n",
      "a  3  4  5  4  5\n",
      "y  4  5  6  5  4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# testing our implementation \n",
    "source =  'play'\n",
    "target = 'stay'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list('#' + source)\n",
    "cols = list('#' + target)\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  3 \n",
      "\n",
      "   #  n  e  a  r\n",
      "#  0  1  2  3  4\n",
      "e  1  2  1  2  3\n",
      "e  2  3  2  3  4\n",
      "r  3  4  3  4  3\n"
     ]
    }
   ],
   "source": [
    "#Test 2\n",
    "\n",
    "source =  'eer'\n",
    "target = 'near'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list(source)\n",
    "idx.insert(0, '#')\n",
    "cols = list(target)\n",
    "cols.insert(0, '#')\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5 - Backtrace \n",
    "\n",
    "\n",
    "Once we have computed your matrix using minimum edit distance, how would find the shortest path from the top left corner to the bottom right corner? \n",
    "\n",
    "Note that we could use backtrace algorithm to find the shortest path given the matrix that our `min_edit_distance` function returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4ff3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def backtrace(source, target, matrix):\n",
    "    i = len(source)\n",
    "    j = len(target)\n",
    "    actions = []\n",
    "\n",
    "    while i > 0 or j > 0:\n",
    "        current_cost = matrix[i][j]\n",
    "\n",
    "        # Check for a match or substitution\n",
    "        if i > 0 and j > 0:\n",
    "            if source[i - 1] == target[j - 1]:\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "\n",
    "            elif matrix[i - 1][j - 1] < current_cost:\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "                actions.append('Replace')\n",
    "            elif i > 0 and matrix[i - 1][j] + 1 == current_cost:\n",
    "                i -= 1\n",
    "                actions.append('Delete')\n",
    "            elif j > 0 and matrix[i][j - 1] + 1 == current_cost:\n",
    "                j -= 1\n",
    "                actions.append('Insert')\n",
    "        elif i > 0:  # Only deletions are possible\n",
    "            i -= 1\n",
    "            actions.append('Delete')\n",
    "        elif j > 0:  # Only insertions are possible\n",
    "            j -= 1\n",
    "            actions.append('Insert')\n",
    "\n",
    "    actions.reverse()\n",
    "    return actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e17f8653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  3 \n",
      "\n",
      "   #  n  e  a  r\n",
      "#  0  1  2  3  4\n",
      "e  1  2  1  2  3\n",
      "e  2  3  2  3  4\n",
      "r  3  4  3  4  3\n"
     ]
    }
   ],
   "source": [
    "# Same Test\n",
    "source =  'eer'\n",
    "target = 'near'\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \",min_edits, \"\\n\")\n",
    "idx = list(source)\n",
    "idx.insert(0, '#')\n",
    "cols = list(target)\n",
    "cols.insert(0, '#')\n",
    "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fcb2180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Insert', 'Replace']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtrace(source, target, matrix)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
